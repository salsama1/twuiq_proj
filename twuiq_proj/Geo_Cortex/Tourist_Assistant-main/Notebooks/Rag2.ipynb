{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='uuid: dca9674273a7576fe3efa7e28e5c7813eb40265f373fa73da5d66d98f83cbdfa\n",
      "poi_name: Sultan Restaurant\n",
      "lat: 29.540509\n",
      "lng: 30.979346\n",
      "reviews_no: 1.0\n",
      "price_range: \n",
      "category: Restaurant' metadata={'source': 'F:/AI_APPS/Tourist_Assistant/Notebooks/cairo_restaurants_cleaned.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cae93",
   "metadata": {},
   "source": [
    "## Creating Index vector database with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c40ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loading CSV files with LangChain\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "csv_path = r\"F:/AI_APPS/Tourist_Assistant/Notebooks/cairo_restaurants_cleaned.csv\"\n",
    "\n",
    "# Load CSV rows as documents\n",
    "loader = CSVLoader(file_path=csv_path,csv_args={\"delimiter\": \",\", \"quotechar\": '\"'},encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Optional: print first document\n",
    "print(documents[0])\n",
    "\n",
    "# Step 2: Split into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,      # Max size of each chunk\n",
    "    chunk_overlap=50     # Overlap between chunks to preserve context\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Optional: See the first chunk\n",
    "print(chunks[0].page_content)\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# Step 2: Create embeddings\n",
    "embeddings = OpenAIEmbeddings()  # You must have OPENAI_API_KEY set in env\n",
    "\n",
    "# Step 3: Store chunks in FAISS vector store\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# Optional: Save vectorstore locally\n",
    "vectorstore.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03c0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF files\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Load embeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(r\"F:\\AI_APPS\\Tourist_Assistant\\Data\\Rules.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "## Use Hugging Face Embeddings (e.g., all-MiniLM-L6-v2)\n",
    "#embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# Create vectorstore with FAISS\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Save the vectorstore locally\n",
    "vectorstore.save_local(\"Rules_final_vectorstore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3924dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF files\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Load embeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(r\"F:\\AI_APPS\\Tourist_Assistant\\Data\\egypt-brochure.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "## Use Hugging Face Embeddings (e.g., all-MiniLM-L6-v2)\n",
    "#embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# Create vectorstore with FAISS\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Save the vectorstore locally\n",
    "vectorstore.save_local(\"brochure_final_vectorstore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b9a41",
   "metadata": {},
   "source": [
    "## Loading Faiss index and testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec3c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanye\\AppData\\Local\\Temp\\ipykernel_20568\\681860109.py:14: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(),  # You can also use OpenAI(model=\"gpt-3.5-turbo\")\n",
      "C:\\Users\\hanye\\AppData\\Local\\Temp\\ipykernel_20568\\681860109.py:21: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the context provided, \"Butcher and restaurant Well done\" might be a good option for a restaurant that serves good meat.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings() \n",
    "# Step 1: Load your saved vector store\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", OpenAIEmbeddings(),allow_dangerous_deserialization=True)\n",
    "\n",
    "# Step 2: Initialize retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 3: Build QA chain using retriever + LLM\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),  # You can also use OpenAI(model=\"gpt-3.5-turbo\")\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Step 4: Ask a question\n",
    "query = \"What is the restaurant which have good meet?\"\n",
    "response = qa_chain(query)\n",
    "\n",
    "# Print answer\n",
    "print(\"Answer:\", response['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61145d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739287af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanye\\AppData\\Local\\Temp\\ipykernel_22760\\3689664857.py:24: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "C:\\Users\\hanye\\AppData\\Local\\Temp\\ipykernel_22760\\3689664857.py:45: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa_chain.run(query)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries from LangChain\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# Ensure you have the OpenAI API key set in your environment\n",
    " \n",
    "embeddings = OpenAIEmbeddings() \n",
    "\n",
    "# Load the webpage\n",
    "url = \"https://www.atlys.com/blog/rules-to-follow-in-egypt\"  # Replace with your URL\n",
    "loader = WebBaseLoader(url)\n",
    "documents = loader.load()\n",
    "\n",
    "# Generate embeddings for the documents using OpenAI's embeddings model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create a FAISS index to store the embeddings\n",
    "vector_store = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Save the FAISS index to disk (optional)\n",
    "vector_store.save_local(\"faiss_index_rules_egypt\")\n",
    "\n",
    "# Set up a retriever to retrieve relevant documents from the vector store\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Initialize the OpenAI model (or any other LLM you prefer)\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Set up the RetrievalQA chain with the retriever and LLM\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Define a query to retrieve the answer from the documents\n",
    "query = \"Entry requirements for Egypt?\"  # Example query\n",
    "\n",
    "# Get the answer from the model\n",
    "answer = qa_chain.run(query)\n",
    "\n",
    "# Print the answer\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabb340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.atlys.com/blog/rules-to-follow-in-egypt', 'title': 'Attention Required! | Cloudflare', 'language': 'en-US'}, page_content='\\n\\n\\n\\n  \\n\\nAttention Required! | Cloudflare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPlease enable cookies.\\n\\n\\nSorry, you have been blocked\\nYou are unable to access atlys.com\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhy have I been blocked?\\nThis website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.\\n\\n\\nWhat can I do to resolve this?\\nYou can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.\\n\\n\\n\\n\\n\\nCloudflare Ray ID: 93d8323d2b9ec986\\nâ€¢\\n\\n      Your IP:\\n      Click to reveal\\n37.224.52.18\\nâ€¢\\n\\nPerformance & security by Cloudflare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93dd07a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\AI_APPS\\Tourist_Assistant\\Notebooks\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a491a8a",
   "metadata": {},
   "source": [
    "## Testing the model with Routing for multi document retrieval and data storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6218596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ae8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "embeddings = OpenAIEmbeddings() \n",
    "\n",
    "# Load vectorstores\n",
    "pdf_vectorstore = FAISS.load_local(\"Rules_final_vectorstore\", embeddings,allow_dangerous_deserialization=True)  # assuming you saved it similarly\n",
    "csv_vectorstore = FAISS.load_local(\"brochure_final_vectorstore\", embeddings,allow_dangerous_deserialization=True)  # assuming you saved it similarly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b264f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanye\\AppData\\Local\\Temp\\ipykernel_20568\\923730309.py:20: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Import necessary libraries from LangChain\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize the OpenAI model (or any other LLM you prefer)\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "# Updated prompt templates with {context}\n",
    "Rules_template = \"\"\"You are a knowledgeable lawyer specializing in tourism laws in Egypt.\n",
    "Use the following context to help answer the question:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\"\"\"\n",
    "\n",
    "restaurant_template = \"\"\"You are a highly experienced tour guide specializing in restaurants.\n",
    "Use the following context to help answer the question:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\"\"\"\n",
    "\n",
    "template_map = {\n",
    "    \"rules\": PromptTemplate.from_template(Rules_template),\n",
    "    \"restaurant\": PromptTemplate.from_template(restaurant_template),\n",
    "}\n",
    "\n",
    "retrievers = {\n",
    "    \"rules\": pdf_vectorstore.as_retriever(search_kwargs={\"k\": 4}),\n",
    "    \"restaurant\": csv_vectorstore.as_retriever(search_kwargs={\"k\": 4}),\n",
    "}\n",
    "\n",
    "prompt_templates = [Rules_template, restaurant_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "# Routing\n",
    "def prompt_router(input):\n",
    "    query = input.get(\"query\", \"\")\n",
    "    if not query or not isinstance(query, str):\n",
    "        raise ValueError(\"Query must be a valid string\")\n",
    "\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    source_key = \"rules\" if most_similar == Rules_template else \"restaurant\"\n",
    "\n",
    "    print(f\"ðŸ”€ Routed to: {source_key}\")\n",
    "    retriever = retrievers[source_key]\n",
    "    context = \"\\n\".join(doc.page_content for doc in retriever.get_relevant_documents(query))\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"context\": context,\n",
    "        \"prompt\": template_map[source_key]\n",
    "    }\n",
    "\n",
    "# Final chain\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | RunnableLambda(lambda input: input[\"prompt\"].format(query=input[\"query\"], context=input[\"context\"]))\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd17de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”€ Routed to: rules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanye\\AppData\\Local\\Temp\\ipykernel_20568\\923730309.py:65: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  context = \"\\n\".join(doc.page_content for doc in retriever.get_relevant_documents(query))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer:\n",
      "Photography is allowed in many sites in Egypt, but flash photography is prohibited in museums and tombs as it can damage artifacts. It is also important to ask for consent before taking pictures of locals and to be mindful of restricted areas such as military installations, airports, and some museums. In mosques, it is important to remove shoes before entering, dress conservatively, and observe silence or speak in a low voice. It is also illegal for foreign visitors to engage in any form of political activity, including photographing protests. Ride-hailing apps like Uber and Careem are popular and safe for navigating cities, but traditional taxis may try to overcharge tourists.\n"
     ]
    }
   ],
   "source": [
    "# Test the chain\n",
    "response = chain.invoke(\"What are the tourist guidelines in Egypt regarding photography?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cfa277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b0c0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”€ Routed to: rules\n",
      "In Egypt, tourists are generally allowed to take photographs for personal use in public spaces. However, there are important exceptions to be aware of. Photography is typically restricted in certain religious sites, such as mosques and churches, where permission may be required. Additionally, taking photographs in military zones or of military personnel and installations is prohibited without explicit permission. It's always advisable for tourists to look for signage indicating photography restrictions and to ask for permission when in doubt, especially in sensitive areas. Respecting these guidelines helps ensure a respectful and lawful visit.\n",
      "ðŸ”€ Routed to: rules\n",
      "While I specialize in tourism laws, I can certainly suggest a popular traditional Egyptian restaurant in Cairo. One highly recommended option is Abou El Sid. It is well-known for its authentic Egyptian cuisine and offers a wide variety of traditional dishes in a charming, vintage setting. Enjoy your meal!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings # Assuming you have this configured\n",
    "from langchain_openai import ChatOpenAI # Assuming you have this configured\n",
    "\n",
    "# Mocking these for demonstration purposes if you don't have them set up\n",
    "# In your actual code, these would be initialized correctly\n",
    "class MockVectorstore:\n",
    "    def as_retriever(self, search_kwargs):\n",
    "        class MockRetriever:\n",
    "            def get_relevant_documents(self, query):\n",
    "                # Simulate document retrieval\n",
    "                if \"tourist guidelines\" in query.lower():\n",
    "                    return [\n",
    "                        type('obj', (object,), {'page_content': \"Photography is generally allowed for personal use in public spaces, but not in certain religious sites or military zones without permission.\"})\n",
    "                    ]\n",
    "                elif \"restaurants\" in query.lower():\n",
    "                    return [\n",
    "                        type('obj', (object,), {'page_content': \"Cairo offers a wide range of restaurants, from traditional Egyptian cuisine to international options. Tipping is customary.\"})\n",
    "                    ]\n",
    "                return []\n",
    "        return MockRetriever()\n",
    "\n",
    "class MockEmbeddings:\n",
    "    def embed_documents(self, texts):\n",
    "        # Simulate embedding for prompt templates\n",
    "        return [[0.1, 0.2] if \"rules\" in text else [0.3, 0.4] for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        # Simulate embedding for queries\n",
    "        if \"photography\" in text.lower() or \"guidelines\" in text.lower():\n",
    "            return [0.15, 0.25] # Closer to rules\n",
    "        return [0.35, 0.45] # Closer to restaurants\n",
    "\n",
    "# Initialize mock components\n",
    "embeddings = MockEmbeddings()\n",
    "pdf_vectorstore = MockVectorstore()\n",
    "csv_vectorstore = MockVectorstore()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0) # Replace with your actual LLM instance\n",
    "\n",
    "# Updated prompt templates with {context}\n",
    "Rules_template = \"\"\"You are a knowledgeable lawyer specializing in tourism laws in Egypt.\n",
    "Use the following context to help answer the question:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\"\"\"\n",
    "\n",
    "restaurant_template = \"\"\"You are a highly experienced tour guide specializing in restaurants.\n",
    "Use the following context to help answer the question:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\"\"\"\n",
    "\n",
    "template_map = {\n",
    "    \"rules\": PromptTemplate.from_template(Rules_template),\n",
    "    \"restaurant\": PromptTemplate.from_template(restaurant_template),\n",
    "}\n",
    "\n",
    "retrievers = {\n",
    "    \"rules\": pdf_vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    \"restaurant\": csv_vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "}\n",
    "\n",
    "prompt_templates = [Rules_template, restaurant_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "# Routing\n",
    "def prompt_router(input_dict): # Renamed 'input' to 'input_dict' for clarity\n",
    "    query = input_dict.get(\"query\", \"\")\n",
    "    if not query or not isinstance(query, str):\n",
    "        raise ValueError(\"Query must be a valid string\")\n",
    "\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar_template_content = prompt_templates[similarity.argmax()] # Get the actual template string\n",
    "    source_key = \"rules\" if most_similar_template_content == Rules_template else \"restaurant\"\n",
    "\n",
    "    print(f\"ðŸ”€ Routed to: {source_key}\")\n",
    "    retriever = retrievers[source_key]\n",
    "    context = \"\\n\".join(doc.page_content for doc in retriever.get_relevant_documents(query))\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"context\": context,\n",
    "        \"prompt\": template_map[source_key]\n",
    "    }\n",
    "\n",
    "# Final chain\n",
    "chain = (\n",
    "    # This ensures the input to prompt_router is always {\"query\": <your_string_query>}\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    # The next RunnableLambda now expects a dictionary with 'prompt', 'query', and 'context'\n",
    "    | RunnableLambda(lambda x: x[\"prompt\"].format(query=x[\"query\"], context=x[\"context\"]))\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test the chain\n",
    "response = chain.invoke(\n",
    "    \"What are the tourist guidelines in Egypt regarding photography?\"\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Test with a restaurant query\n",
    "response_restaurant = chain.invoke(\n",
    "    \"Suggest a good traditional Egyptian restaurant in Cairo.\"\n",
    ")\n",
    "print(response_restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d65918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a restaurant query\n",
    "response_restaurant = chain.invoke(\n",
    "    \"Suggest a good traditional Egyptian restaurant in Cairo.\"\n",
    ")\n",
    "print(response_restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935dcf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
